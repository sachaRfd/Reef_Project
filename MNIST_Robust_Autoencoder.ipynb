{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy2IUZEn4Tcv+Jt/z0/8n4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sachaRfd/Reef_Project/blob/main/MNIST_Robust_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFl2VBHmW0Ld"
      },
      "outputs": [],
      "source": [
        "! pip install tensorflow\n",
        "! pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "def batches(l, n):\n",
        "    \"\"\"Yield successive n-sized batches from l, the last batch is the left indexes.\"\"\"\n",
        "    for i in range(0, l, n):\n",
        "        yield range(i,min(l,i+n))\n",
        "\n",
        "class Deep_Autoencoder(object):\n",
        "    def __init__(self, sess, input_dim_list=[784,400]):\n",
        "        \"\"\"input_dim_list must include the original data dimension\"\"\"\n",
        "        assert len(input_dim_list) >= 2\n",
        "        self.W_list = []\n",
        "        self.encoding_b_list = []\n",
        "        self.decoding_b_list = []\n",
        "        self.dim_list = input_dim_list\n",
        "        self.learning_rate = tf.compat.v1.placeholder(tf.float32, shape=())\n",
        "        ## Encoders parameters\n",
        "        for i in range(len(input_dim_list)-1):\n",
        "            init_max_value = np.sqrt(6. / (self.dim_list[i] + self.dim_list[i+1]))\n",
        "            self.W_list.append(tf.Variable(tf.random.uniform([self.dim_list[i],self.dim_list[i+1]],\n",
        "                                                             np.negative(init_max_value),init_max_value)))\n",
        "            self.encoding_b_list.append(tf.Variable(tf.random.uniform([self.dim_list[i+1]],-0.1,0.1)))\n",
        "        ## Decoders parameters\n",
        "        for i in range(len(input_dim_list)-2,-1,-1):\n",
        "            self.decoding_b_list.append(tf.Variable(tf.random.uniform([self.dim_list[i]],-0.1,0.1)))\n",
        "        ## Placeholder for input\n",
        "        self.input_x = tf.compat.v1.placeholder(tf.float32,[None,self.dim_list[0]])\n",
        "        ## coding graph :\n",
        "        last_layer = self.input_x\n",
        "        for weight,bias in zip(self.W_list,self.encoding_b_list):\n",
        "            hidden = tf.sigmoid(tf.matmul(last_layer,weight) + bias)\n",
        "            last_layer = hidden\n",
        "        self.hidden = hidden \n",
        "        ## decode graph:\n",
        "        for weight,bias in zip(reversed(self.W_list),self.decoding_b_list):\n",
        "            hidden = tf.sigmoid(tf.matmul(last_layer,tf.transpose(weight)) + bias)\n",
        "            last_layer = hidden\n",
        "        self.recon = last_layer\n",
        "   \n",
        "        self.cost = 200 * tf.reduce_mean(tf.square(self.input_x - self.recon))\n",
        "#         self.cost = 200*tf.losses.log_loss(self.recon, self.input_x)\n",
        "        self.train_step = tf.compat.v1.train.AdamOptimizer(self.learning_rate).minimize(self.cost)\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "    def fit(self, X, sess, learning_rate=0.15,\n",
        "            iteration=200, batch_size=50, init=False,verbose=False):\n",
        "        assert X.shape[1] == self.dim_list[0]\n",
        "        if init:\n",
        "            sess.run(tf.global_variables_initializer())\n",
        "        sample_size = X.shape[0]\n",
        "        for i in range(iteration):\n",
        "            for one_batch in batches(sample_size, batch_size):\n",
        "                sess.run(self.train_step,feed_dict = {self.input_x:X[one_batch], self.learning_rate: learning_rate})\n",
        "\n",
        "            if verbose and i%20==0:\n",
        "                e = self.cost.eval(session = sess,feed_dict = {self.input_x: X})\n",
        "                print (\"    iteration : \", i ,\", cost : \", e)\n",
        "\n",
        "    def transform(self, X, sess):\n",
        "        return self.hidden\n",
        "\n",
        "    def getRecon(self, X, sess):\n",
        "        return self.recon.eval(session = sess,feed_dict={self.input_x: X})\n",
        "    \n",
        "##################### test a machine with different data size#####################  \n",
        "def test():\n",
        "    start_time = time.time()\n",
        "    with tf.Session() as sess:\n",
        "        ae = Deep_Autoencoder(sess = sess, input_dim_list=[784,625,400,225,100])\n",
        "        error = ae.fit(x[:1000] ,sess = sess, learning_rate=0.01, batch_size = 500, iteration = 1000, verbose=False)\n",
        "\n",
        "    print (\"size 1000 Runing time:\" + str(time.time() - start_time) + \" s\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    with tf.Session() as sess:\n",
        "        ae = Deep_Autoencoder(sess = sess, input_dim_list=[784,625,400,225,100])\n",
        "        error = ae.fit(x[:10000] ,sess = sess, learning_rate=0.01, batch_size = 500, iteration = 1000, verbose=False)\n",
        "\n",
        "    print (\"size 10,000 Runing time:\" + str(time.time() - start_time) + \" s\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    with tf.Session() as sess:\n",
        "        ae = Deep_Autoencoder(sess = sess, input_dim_list=[784,625,400,225,100])\n",
        "        error = ae.fit(x[:20000] ,sess = sess, learning_rate=0.01, batch_size = 500, iteration = 1000, verbose=False)\n",
        "\n",
        "    print (\"size 20,000 Runing time:\" + str(time.time() - start_time) + \" s\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    with tf.Session() as sess:\n",
        "        ae = Deep_Autoencoder(sess = sess, input_dim_list=[784,625,400,225,100])\n",
        "        error = ae.fit(x[:50000] ,sess = sess, learning_rate=0.01, batch_size = 500, iteration = 1000, verbose=False)\n",
        "\n",
        "    print (\"size 50,000 Runing time:\" + str(time.time() - start_time) + \" s\")"
      ],
      "metadata": {
        "id": "7icXJIkKW58t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.load(\"/content/stuff/data.npk\", allow_pickle=True)"
      ],
      "metadata": {
        "id": "ENmb5KSXW9PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  ae = Deep_Autoencoder(sess, input_dim_list=[784,225,100])\n",
        "  error = ae.fit(x, sess, learning_rate = 0.01, batch_size = 100, iteration = 10, verbose = True)\n",
        "  #R = ae.getRecon(x, sess = sess)\n",
        "  #error = ae.fit(R ,sess = sess, learning_rate=0.01, batch_size = 100, iteration = 100, verbose=True)\n",
        "\n",
        "  # Get the reconstructed images\n",
        "  recon_images = ae.getRecon(x, sess=sess)\n",
        "\n",
        "  # Plot some of the reconstructed images\n",
        "  n = 10  # Number of images to plot\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "      # Display original image\n",
        "      ax = plt.subplot(2, n, i + 1)\n",
        "      plt.imshow(x[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "\n",
        "      # Display reconstructed image\n",
        "      ax = plt.subplot(2, n, i + 1 + n)\n",
        "      plt.imshow(recon_images[i].reshape(28, 28))\n",
        "      plt.gray()\n",
        "      ax.get_xaxis().set_visible(False)\n",
        "      ax.get_yaxis().set_visible(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "l9O72r-xW-_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def shrink(epsilon, x):\n",
        "    \"\"\"\n",
        "    @Original Author: Prof. Randy\n",
        "    @Modified by: Chong Zhou\n",
        "    update to python3: 03/15/2019\n",
        "    Args:\n",
        "        epsilon: the shrinkage parameter (either a scalar or a vector)\n",
        "        x: the vector to shrink on\n",
        "\n",
        "    Returns:\n",
        "        The shrunk vector\n",
        "    \"\"\"\n",
        "    output = np.array(x*0.)\n",
        "\n",
        "    for idx, ele in enumerate(x):\n",
        "        if ele > epsilon:\n",
        "            output[idx] = ele - epsilon\n",
        "        elif ele < -epsilon:\n",
        "            output[idx] = ele + epsilon\n",
        "        else:\n",
        "            output[idx] = 0.\n",
        "    return output"
      ],
      "metadata": {
        "id": "1HRPdG0ZXDcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import numpy.linalg as nplin\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class RDAE(object):\n",
        "    \"\"\"\n",
        "    @author: Chong Zhou\n",
        "    2.0 version.\n",
        "    complete: 10/17/2016\n",
        "    version changes: move implementation from theano to tensorflow.\n",
        "    3.0\n",
        "    complete: 2/12/2018\n",
        "    changes: delete unused parameter, move shrink function to other file\n",
        "    update: 03/15/2019\n",
        "        update to python3 \n",
        "    Des:\n",
        "        X = L + S\n",
        "        L is a non-linearly low rank matrix and S is a sparse matrix.\n",
        "        argmin ||L - Decoder(Encoder(L))|| + ||S||_1\n",
        "        Use Alternating projection to train model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sess, layers_sizes, lambda_=1.0, error=1.0e-7):\n",
        "        \"\"\"\n",
        "        sess: a Tensorflow tf.Session object\n",
        "        layers_sizes: a list that contain the deep ae layer sizes, including the input layer\n",
        "        lambda_: tuning the weight of l1 penalty of S\n",
        "        error: converge criterior for jump out training iteration\n",
        "        \"\"\"\n",
        "        self.lambda_ = lambda_\n",
        "        self.layers_sizes = layers_sizes\n",
        "        self.error = error\n",
        "        self.errors = []\n",
        "        self.AE = Deep_Autoencoder(\n",
        "            sess=sess, input_dim_list=self.layers_sizes)\n",
        "\n",
        "    def fit(self, X, sess, learning_rate=0.15, inner_iteration=50,\n",
        "            iteration=20, batch_size=50, verbose=False):\n",
        "        # The first layer must be the input layer, so they should have same sizes.\n",
        "        assert X.shape[1] == self.layers_sizes[0]\n",
        "\n",
        "        # initialize L, S, mu(shrinkage operator)\n",
        "        self.L = np.zeros(X.shape)\n",
        "        self.S = np.zeros(X.shape)\n",
        "\n",
        "        mu = (X.size) / (4.0 * nplin.norm(X, 1))\n",
        "        print(\"shrink parameter:\", self.lambda_ / mu)\n",
        "        LS0 = self.L + self.S\n",
        "\n",
        "        XFnorm = nplin.norm(X, 'fro')\n",
        "        if verbose:\n",
        "            print(\"X shape: \", X.shape)\n",
        "            print(\"L shape: \", self.L.shape)\n",
        "            print(\"S shape: \", self.S.shape)\n",
        "            print(\"mu: \", mu)\n",
        "            print(\"XFnorm: \", XFnorm)\n",
        "\n",
        "        for it in range(iteration):\n",
        "            if verbose:\n",
        "                print(\"Out iteration: \", it)\n",
        "            # alternating project, first project to L\n",
        "            self.L = X - self.S\n",
        "            # Using L to train the auto-encoder\n",
        "            self.AE.fit(X=self.L, sess=sess,\n",
        "                        iteration=inner_iteration,\n",
        "                        learning_rate=learning_rate,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=verbose)\n",
        "            # get optmized L\n",
        "            self.L = self.AE.getRecon(X=self.L, sess=sess)\n",
        "            # alternating project, now project to S\n",
        "            self.S = shrink(\n",
        "                self.lambda_/mu, (X - self.L).reshape(X.size)).reshape(X.shape)\n",
        "\n",
        "            # break criterion 1: the L and S are close enough to X\n",
        "            c1 = nplin.norm(X - self.L - self.S, 'fro') / XFnorm\n",
        "            # break criterion 2: there is no changes for L and S\n",
        "            c2 = np.min([mu, np.sqrt(mu)]) * \\\n",
        "                nplin.norm(LS0 - self.L - self.S) / XFnorm\n",
        "\n",
        "            if verbose:\n",
        "                print(\"c1: \", c1)\n",
        "                print(\"c2: \", c2)\n",
        "\n",
        "            if c1 < self.error and c2 < self.error:\n",
        "                print(\"early break\")\n",
        "                break\n",
        "            # save L + S for c2 check in the next iteration\n",
        "            LS0 = self.L + self.S\n",
        "\n",
        "        return self.L, self.S\n",
        "\n",
        "    def transform(self, X, sess):\n",
        "        L = X - self.S\n",
        "        return self.AE.transform(X=L, sess=sess)\n",
        "\n",
        "    def getRecon(self, X, sess):\n",
        "        return self.AE.getRecon(X, sess=sess)"
      ],
      "metadata": {
        "id": "iFcZRXROXE49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = x[:500]\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "  rae = RDAE(sess=sess, lambda_=2000, layers_sizes=[784, 400])\n",
        "  L, S = rae.fit(x, sess=sess, learning_rate=0.01, batch_size=40, inner_iteration=50,\n",
        "                       iteration=5, verbose=True)\n",
        "  recon_rae = rae.getRecon(x, sess=sess)\n",
        "  print(\"cost errors, not used for now:\", rae.errors)"
      ],
      "metadata": {
        "id": "ajovYETgXGrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for i in range(10):\n",
        "  orig = x[i].reshape(28,28)\n",
        "  recon = recon_rae[i].reshape(28,28)\n",
        "  print(f\"This is the {i} th image:\")\n",
        "  print(\"Original\")\n",
        "  plt.imshow(orig)\n",
        "  plt.show()\n",
        "  print(\"Reconstructed:\")\n",
        "  plt.imshow(recon)\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "rF6kQQdJXILD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}